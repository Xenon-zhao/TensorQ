{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们展示一个制备35比特GHZ态的线路，用MindQuantum模拟将需要256GB内存，导致MindQuantum报错无法模拟。而使用tensorq可以完成模拟。\n",
    "\n",
    "首先，我们用MindQuantum模拟10比特的类似线路，验证代码的正确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0: ──H────●──────────────────────────────────────────\n",
      "           │\n",
      "q1: ───────X────●─────────────────────────────────────\n",
      "                │\n",
      "q2: ────────────X────●────────────────────────────────\n",
      "                     │\n",
      "q3: ─────────────────X────●───────────────────────────\n",
      "                          │\n",
      "q4: ──────────────────────X────●──────────────────────\n",
      "                               │\n",
      "q5: ───────────────────────────X────●─────────────────\n",
      "                                    │\n",
      "q6: ────────────────────────────────X────●────────────\n",
      "                                         │\n",
      "q7: ─────────────────────────────────────X────●───────\n",
      "                                              │\n",
      "q8: ──────────────────────────────────────────X────●──\n",
      "                                                   │\n",
      "q9: ───────────────────────────────────────────────X──\n",
      "mqvector simulator with 10 qubits (little endian).\n",
      "Current quantum state:\n",
      "[0.70710678+0.j 0.        +0.j 0.        +0.j ... 0.        +0.j\n",
      " 0.        +0.j 0.70710678+0.j]\n"
     ]
    }
   ],
   "source": [
    "# 构造线路\n",
    "import numpy as np                                          # 导入numpy库并简写为np\n",
    "from mindquantum.core.gates import X, Y, Z, H, RX, RY, RZ, CNOT, CNOTGate, FSim   # 导入量子门H, X, Y, Z, RX, RY, RZ\n",
    "from mindquantum.core.circuit import Circuit     # 导入Circuit模块，用于搭建量子线路\n",
    "\n",
    "n = 10\n",
    "CIRCUIT = Circuit()                              # 初始化量子线路\n",
    "CIRCUIT += H.on(0)                               # H门作用在第0位量子比特\n",
    "for i in range(n-1):\n",
    "    CIRCUIT += CNOTGate().on(obj_qubits=i+1, ctrl_qubits=i)\n",
    "\n",
    "encoder = CIRCUIT\n",
    "print(encoder)                                   # 打印Encoder\n",
    "\n",
    "# 模拟线路\n",
    "from mindquantum.simulator import Simulator    # 从mindquantum.simulator中导入Simulator类\n",
    "sim = Simulator('mqvector', n)   #声明一个一比特的mqvector模拟器\n",
    "\n",
    "sim.apply_circuit(CIRCUIT)  #作用一个量子线路，当线路是一个参数化量子线路时，我们还需要提供参数值。\n",
    "print(sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "成功制备了10比特GHZ态，接下来我们把n设置为35，表示模拟35比特的线路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 构造线路\n",
    "import numpy as np                                          # 导入numpy库并简写为np\n",
    "from mindquantum.core.gates import X, Y, Z, H, RX, RY, RZ, CNOT, CNOTGate, FSim   # 导入量子门H, X, Y, Z, RX, RY, RZ\n",
    "from mindquantum.core.circuit import Circuit     # 导入Circuit模块，用于搭建量子线路\n",
    "\n",
    "n = 35\n",
    "CIRCUIT = Circuit()                              # 初始化量子线路\n",
    "CIRCUIT += H.on(0)                               # H门作用在第0位量子比特\n",
    "for i in range(n-1):\n",
    "    CIRCUIT += CNOTGate().on(obj_qubits=i+1, ctrl_qubits=i)\n",
    "\n",
    "encoder = CIRCUIT\n",
    "print(encoder)                                   # 打印Encoder\n",
    "\n",
    "# 模拟线路\n",
    "from mindquantum.simulator import Simulator    # 从mindquantum.simulator中导入Simulator类\n",
    "sim = Simulator('mqvector', n)   #声明一个一比特的mqvector模拟器\n",
    "\n",
    "sim.apply_circuit(CIRCUIT)  #作用一个量子线路，当线路是一个参数化量子线路时，我们还需要提供参数值。\n",
    "print(sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "报错！需要256GB内存，无法模拟！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们用tensorq模拟同样的线路\n",
    "\n",
    "首先在`circuit.py`文件中构建量子线路，然后用tensorq中的QuantumCircuit将量子子线路转换成张量网络（注意修改`circuit.py`文件后，要Restart，tensorq才能读取到新线路）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorq import QuantumCircuit\n",
    "n = 35\n",
    "qc_n35 = QuantumCircuit(n = n,twoqubit_simplify = False,fname = 'circuit',circuit_package='MindQuantum')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，n = 35表示35个比特；twoqubit_simplify = False表示不进行两比特门优化，因为该线路中两比特门不必优化；fname = 'circuit'表示线路在文件`circuit.py`中。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用tensorq中的search_order搜索缩并方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish find contraction tree, next construct the scheme.\n",
      "Finish construct the scheme.\n",
      "time complexity (tc,log10), space complexity (sc,log2), memory complexity (mc) =  (3.1535099893008374, 4.0, 3.338456493604605)\n"
     ]
    }
   ],
   "source": [
    "from tensorq import search_order\n",
    "contract_scheme = search_order(n = n,device = 'cuda',qc = qc_n35, sc_target = 24, bitstrings_txt = 'two_bitstrings_n35.txt', max_bitstrings=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，n = n表示n个比特；device = 'cuda' 表示用GPU进行计算，用CPU计算使用device = 'cpu'；qc = qc_n35 输入之前定义的量子线路。\n",
    "\n",
    "sc_target = 24表示限制最大张量小于24GB内存，这是tensorq中很核心的一个参数，可以根据自己的设备内存进行设置。同样的缩并任务，内存越大时间复杂度越低，内存越小将会对张量做更多的分解导致更多的浮点运算，这是用时间换空间的办法解决量子模拟中的指数墙困难。\n",
    "\n",
    "bitstrings_txt = 'two_bitstrings_n35.txt' 表示将我们需要计算振幅的比特串写在`two_bitstrings_n35.txt`文件里面，因为只有'00000000000000000000000000000000000', '11111111111111111111111111111111111' 两个比特串的振幅非0，因此这里只计算两个比特串的振幅。\n",
    "\n",
    "max_bitstrings=2，表示最多计算2两个比特串的振幅。\n",
    "\n",
    "search_order会打印该缩并方案的复杂度，时间复杂度为浮点数运算次数，以10为底的对数表示；空间复杂度为最大张量的元素个数（与sc_target单位并不相同），以2为底的对数表示；空间复杂度为最大张量元素个数乘以单个数据的存储大小（与数据类型有关）。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，用tensorq的contraction_single_task对张量进行缩并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fianl amplitue: tensor([0.7071+0.j, 0.7071+0.j])\n"
     ]
    }
   ],
   "source": [
    "from tensorq import contraction_single_task\n",
    "tensors, scheme, slicing_indices, bitstrings = contract_scheme\n",
    "result = contraction_single_task(\n",
    "    tensors,\n",
    "    scheme,\n",
    "    slicing_indices\n",
    ")\n",
    "print('fianl amplitue:', result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contract_scheme中包含了缩并张量tensors，缩并步骤scheme，切片指标slicing_indices（与张量分解有关），计算振幅的比特串bitstrings，将这些变量输入到contraction_single_task，就会返回张量网络的缩并结果，就是全部末态比特串的振幅。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，由于目标比特串比较少，仅通过调整张量网络的缩并顺序就可以避免出现较大的张量，因此search_order中只优化了缩并顺序，并没有采用切片策略来减小张量维度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
